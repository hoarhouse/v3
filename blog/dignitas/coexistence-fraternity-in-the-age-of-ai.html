<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Coexistence: Fraternity in the Age of AI - DCF Hungary Blog</title>
    <link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:ital,wght@0,400;0,600;0,700;1,400;1,600&family=Source+Sans+3:ital,wght@0,300;0,400;0,600;0,700;1,400&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="/v3/css/styles.css">
    <style>
:root {
    --dignitas-deep: #1a1a2e;
    --dignitas-gold: #c9a84c;
    --dignitas-gold-light: #e8d5a0;
    --dignitas-warm: #f7f3eb;
    --dignitas-cream: #faf8f4;
    --dignitas-text: #2c2c3a;
    --dignitas-text-light: #6b6b7b;
    --dignitas-rule: #d4cfc4;
    --dignitas-accent: #8b2332;
    --font-display: 'Cormorant Garamond', Georgia, serif;
    --font-body: 'Source Sans 3', 'Segoe UI', sans-serif;
}

.article-hero {
    background: var(--dignitas-warm);
    border-bottom: 1px solid var(--dignitas-rule);
    padding: 48px 40px 44px;
    text-align: center;
    position: relative;
}
.article-hero::before {
    content: '';
    position: absolute;
    top: 0;
    left: 50%;
    transform: translateX(-50%);
    width: 60px;
    height: 3px;
    background: var(--dignitas-gold);
}
.article-hero .back-link {
    display: inline-block;
    font-size: 12px;
    letter-spacing: 1.5px;
    text-transform: uppercase;
    color: var(--dignitas-gold);
    text-decoration: none;
    margin-bottom: 20px;
}
.article-hero .back-link:hover {
    color: var(--dignitas-accent);
}
.article-hero .article-category-tag {
    font-size: 11px;
    letter-spacing: 2px;
    text-transform: uppercase;
    color: var(--dignitas-accent);
    font-weight: 600;
    margin-bottom: 12px;
}
.article-hero h1 {
    font-family: var(--font-display);
    font-size: clamp(30px, 4vw, 44px);
    font-weight: 600;
    color: var(--dignitas-deep);
    line-height: 1.25;
    max-width: 800px;
    margin: 0 auto 16px;
}
.article-hero .article-meta {
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 12px;
    margin-top: 20px;
}
.article-hero .meta-avatar {
    width: 44px;
    height: 44px;
    border-radius: 50%;
    background: var(--dignitas-deep);
    display: flex;
    align-items: center;
    justify-content: center;
    color: var(--dignitas-gold-light);
    font-family: var(--font-display);
    font-size: 16px;
    font-weight: 600;
}
.article-hero .meta-info {
    text-align: left;
    font-size: 13px;
    line-height: 1.4;
}
.article-hero .meta-name {
    font-weight: 600;
    color: var(--dignitas-deep);
}
.article-hero .meta-detail {
    color: var(--dignitas-text-light);
}

.article-body {
    max-width: 720px;
    margin: 0 auto;
    padding: 48px 40px 64px;
    font-family: var(--font-body);
    font-size: 17px;
    line-height: 1.8;
    color: var(--dignitas-text);
}
.article-body h2 {
    font-family: var(--font-display);
    font-size: 28px;
    font-weight: 600;
    color: var(--dignitas-deep);
    margin: 40px 0 16px;
    line-height: 1.3;
}
.article-body h3 {
    font-family: var(--font-display);
    font-size: 22px;
    font-weight: 600;
    color: var(--dignitas-deep);
    margin: 32px 0 12px;
}
.article-body p {
    margin-bottom: 20px;
}
.article-body blockquote {
    border-left: 3px solid var(--dignitas-gold);
    margin: 32px 0;
    padding: 16px 24px;
    background: var(--dignitas-warm);
    font-family: var(--font-display);
    font-size: 19px;
    font-style: italic;
    color: var(--dignitas-text-light);
    line-height: 1.6;
}
.article-body ul, .article-body ol {
    margin-bottom: 20px;
    padding-left: 24px;
}
.article-body li {
    margin-bottom: 8px;
}
.article-body a {
    color: var(--dignitas-accent);
    text-decoration: underline;
    text-decoration-color: rgba(139,35,50,0.3);
    text-underline-offset: 3px;
}
.article-body a:hover {
    text-decoration-color: var(--dignitas-accent);
}

.article-footer-nav {
    max-width: 720px;
    margin: 0 auto;
    padding: 0 40px 64px;
    border-top: 1px solid var(--dignitas-rule);
    padding-top: 32px;
    text-align: center;
}
.article-footer-nav a {
    display: inline-block;
    font-size: 13px;
    letter-spacing: 1.5px;
    text-transform: uppercase;
    color: var(--dignitas-gold);
    text-decoration: none;
    font-weight: 600;
}
.article-footer-nav a:hover {
    color: var(--dignitas-accent);
}

@media (max-width: 600px) {
    .article-hero { padding: 36px 20px 32px; }
    .article-body { padding: 32px 20px 48px; }
    .article-footer-nav { padding: 0 20px 48px; }
}
    </style>
</head>
<body>
    <nav id="main-nav"></nav>
    
    <div class="article-hero">
        <a href="/v3/blog/dignitas/index.html" class="back-link">← Back to Dignitas</a>
        <div class="article-category-tag">Faith & Technology</div>
        <h1>Coexistence: Fraternity in the Age of AI</h1>
        <div class="article-meta">
            <div class="meta-avatar">DCF</div>
            <div class="meta-info">
                <div class="meta-name">Domus Communis Foundation</div>
                <div class="meta-detail">October 7, 2025 · DCF</div>
            </div>
        </div>
    </div>

    <div class="article-body">
        <p><strong><em>Our global appeal for peaceful human coexistence and shared responsibility</em></strong></p><p><strong>Rome, September 12, 2025</strong></p><p><br></p><p><strong>To:</strong></p><ul><li>His Holiness Pope Leo XIV</li><li>All Global Leaders</li><li>All People of Good Will</li></ul><p><em>(English version — also available in </em><a href="https://hoarhouse.github.io/dcfh/public/dcf_ai_resource_view.html?slug=resource-1759841339531" rel="noopener noreferrer" target="_blank"><em>ar-AE</em></a><em>, de-DE, es-ES, fr-CA, fr-FR, he-IL, hi-IN, it-IT, ja-JP, ko-KR, pt-BR, sv-SE, zh-CN)</em></p><p><br></p><p><strong>Preamble</strong></p><p>Moved by a deep desire for a future where humans shape society and decisions, we—an independent roundtable composed of experts, technology leaders, thought leaders, and scholars from many different nations, backgrounds, and faiths—make the following appeal for a future in which AI must be developed responsibly, by and for the people.</p><p>The choices we make today about AI will fundamentally shape the world we leave to future generations. AI is already causing significant harm: widening inequalities, concentrating power in the hands of a few, and damaging the environment. Vast and rapidly growing sums are being devoted to creating agentic technologies with the potential to surpass human intelligence—what many in the AI research community refer to as “superintelligence.” These challenges call for moral leadership and urgent, concrete actions.</p><p>Artificial intelligence presents significant opportunities to advance scientific discovery and mutual human understanding, transform healthcare, improve governance, and foster sustainable, inclusive prosperity. However, it also poses serious risks—as described in the <em>International Scientific Report on AI Safety</em>—including job displacement, reduction of individual freedoms, power warfare, disinformation, manipulation, mass surveillance, environmental damage, and threats to human welfare.</p><p>To harness legitimate opportunities while mitigating risks, it is essential to establish foundations for human flourishing and clear boundaries rooted in dignity, community, human and environmental rights, and accountability.</p><p><br></p><p><strong>Our Appeal</strong></p><p>In a spirit of fraternity, hope, and caution, we call upon leadership worldwide to uphold the following principles and red lines, fostering dialogue and reflection on how AI can best serve our entire human family:</p><ol><li><strong>Human Life and Dignity</strong></li><li>AI must never be developed or used in ways that threaten, diminish, or disqualify human life, dignity, or fundamental rights. Human intelligence—our capacity for wisdom, moral reasoning, and orientation toward truth and beauty—must never be devalued by artificial processing, however sophisticated.</li><li><strong>AI as a Tool, Not an Authority</strong></li><li>AI must remain under human control. Building uncontrollable systems or over-delegating decisions is morally unacceptable and must be legally prohibited. Development of “superintelligent” AI technologies should not be allowed until there is broad scientific consensus that it can be done safely and controllably, with clear and broad public consent.</li><li><strong>Accountability</strong></li><li>Only humans have moral and legal agency. AI systems are and must remain legal <em>objects</em>, never <em>subjects</em>. Responsibility and liability rest with developers, vendors, companies, deployers, users, institutions, and governments. AI cannot be granted legal personhood or “rights.”</li><li><strong>Life-and-Death Decisions</strong></li><li>AI must never be allowed to make life-or-death decisions—particularly in military conflict, law enforcement, border control, healthcare, or judicial contexts.</li><li><strong>Safe and Ethical Development</strong></li><li>Developers must embed safety, transparency, and ethics into AI from the start. Deployers share equal responsibility. Independent testing and risk assessments must be mandatory before and throughout deployment.</li><li><strong>Stewardship</strong></li><li>Governments and corporations must never weaponize AI for domination, illegal wars of aggression, coercion, manipulation, social scoring, or mass surveillance.</li><li><strong>Responsible Design</strong></li><li>AI must be designed—and independently evaluated—to avoid unintentional or catastrophic effects on humans and society, such as deception, delusion, addiction, or loss of autonomy.</li><li><strong>No AI Monopoly</strong></li><li>The economic, medical, scientific, and social benefits of AI must not be monopolized by any group or nation.</li><li><strong>No Human Devaluation</strong></li><li>AI design and deployment should help humans flourish in their chosen pursuits, not render humanity redundant, disenfranchised, or replaceable.</li><li><strong>Ecological Responsibility</strong></li><li>AI development must not endanger the planet. Its large demands for energy, water, and rare minerals must be managed responsibly and sustainably across the entire supply chain.</li><li><strong>No Irresponsible Global Competition</strong></li><li>Nations and corporations must avoid reckless races toward ever more powerful AI systems.</li></ol><p><br></p><p><strong>Call to Action</strong></p><p>Upholding these principles demands moral courage, accountability, and farsighted leadership. We urge the creation of a <strong>binding international treaty</strong> establishing red lines and an <strong>independent oversight body</strong> with enforcement powers.</p><p>We call on:</p><ul><li><strong>Scientists, civil society, and rights groups</strong> to amplify public awareness of AI’s limitations and dangers.</li><li><strong>Industry and policymakers</strong> to center their work on protecting and benefiting the most vulnerable communities affected by AI’s material costs.</li><li><strong>Auditors and researchers</strong> to develop new metrics for evaluating AI—focused on veracity, balance, and human good, not just performance or engagement.</li><li><strong>Governments and global communities</strong> to establish frameworks ensuring that AI governance serves the common good, including the right to live free from AI intrusion.</li></ul><p>The advancement of genuine human fraternity in the age of artificial intelligence requires <strong>universal ethical and legal standards.</strong></p><p>Finally, we appeal to all people of good will: let us unite to ensure that AI serves all humanity rather than a narrow few. By coming together across nations, cultures, and creeds—prioritizing dialogue over competition—we can shape a future that uplifts human dignity and fosters a just and peaceful world.</p><p><br></p><p><strong>Working Group Members (Drafters of the Global Appeal)</strong></p><ol><li>Paolo Benanti <em>(Scientific Coordinator)</em></li><li>Yoshua Bengio</li><li>Ernesto Belisario</li><li>Abeba Birhane</li><li>Cornelius Boersch</li><li>Yuval Noah Harari</li><li>Geoffrey Hinton</li><li>Lorena Jaume-Palasí</li><li>Antal Kuthy</li><li>Riccardo Luna <em>(Coordinator)</em></li><li>Nnenna Nwakanma</li><li>Valerie Pisano</li><li>Stuart Russell</li><li>Max Tegmark</li><li>Marco Trombetti</li><li>Jimena Sofía Viveros Álvarez</li><li>Alexander Waibel</li><li>will.i.am</li></ol><p><strong>Also signed by:</strong></p><ul><li>Miguel Benasayag</li><li>Giorgio Parisi</li><li>Maria Ressa</li></ul><p><br></p>
    </div>

    <div class="article-footer-nav">
        <a href="/v3/blog/dignitas/index.html">← Back to Dignitas</a>
    </div>
    
    <footer id="main-footer"></footer>
    
    <script src="/v3/js/nav.js"></script>
    <script src="/v3/js/main.js"></script>
</body>
</html>