<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI in Healthcare: Catholic Medical Ethics Guide - DCF - FAQ</title>
    <meta name="description" content="Catholic teaching on AI in healthcare, medical ethics, and doctor-patient relationships. Vatican guidance on when to trust machines with life and death.">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><circle cx='50' cy='50' r='40' fill='%23dc3545'/></svg>">
    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            background: #f8f9fa;
        }

        .header {
            background: white;
            border-bottom: 1px solid #e5e5e5;
            padding: 1rem 0;
            position: sticky;
            top: 0;
            z-index: 100;
        }

        .nav-container {
            max-width: 1200px;
            margin: 0 auto;
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 0 2rem;
        }

        .logo {
            display: flex;
            align-items: center;
            font-weight: 600;
            color: #333;
            text-decoration: none;
        }

        .logo-text {
            font-size: 0.95rem;
        }

        .logo-icon {
            width: 24px;
            height: 24px;
            background: #333;
            border-radius: 50%;
            margin-right: 8px;
        }

        .nav-menu {
            display: flex;
            list-style: none;
            gap: 2rem;
        }

        .nav-menu a {
            text-decoration: none;
            color: #666;
            font-size: 0.9rem;
        }

        .nav-menu a:hover {
            color: #333;
        }

        .user-menu {
            display: flex;
            align-items: center;
            gap: 1rem;
        }

        .language-buttons {
            display: flex;
            gap: 0.5rem;
        }

        .lang-btn {
            padding: 0.4rem 0.8rem;
            background: transparent;
            border: 1px solid #e5e5e5;
            border-radius: 6px;
            font-size: 0.85rem;
            font-weight: 600;
            color: #666;
            cursor: pointer;
            transition: all 0.2s ease;
        }

        .lang-btn:hover {
            border-color: #333;
            color: #333;
        }

        .lang-btn.active {
            background: #000;
            color: white;
            border-color: #000;
        }

        .btn {
            padding: 0.75rem 1.5rem;
            border: none;
            border-radius: 8px;
            font-size: 0.9rem;
            cursor: pointer;
            transition: all 0.3s ease;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            font-weight: 600;
        }

        .btn-primary {
            background: #000;
            color: white;
        }

        .btn-primary:hover {
            background: #333;
        }

        @media (max-width: 768px) {
            .nav-menu {
                display: none;
            }
        }

        /* Main Container */
        .main-container {
            max-width: 900px;
            margin: 3rem auto;
            padding: 0 2rem;
        }

        /* Page Header - White Card */
        .page-header {
            background: white;
            border-radius: 16px;
            padding: 3rem;
            margin-bottom: 3rem;
            box-shadow: 0 2px 8px rgba(0,0,0,0.08);
        }

        .page-title {
            font-size: 3rem;
            font-weight: 700;
            color: #333;
            margin-bottom: 1rem;
            line-height: 1.2;
        }

        .page-subtitle {
            font-size: 1.25rem;
            color: #666;
            margin-bottom: 2rem;
        }

        .view-counter {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            color: #666;
            font-size: 0.9rem;
            margin-top: 1rem;
        }

        .view-counter span {
            font-weight: 600;
        }

        /* Table of Contents */
        .toc {
            background: #f8f9fa;
            border-radius: 12px;
            padding: 2rem;
            margin-bottom: 3rem;
        }

        .toc h2 {
            font-size: 1.5rem;
            margin-bottom: 1rem;
            color: #333;
        }

        .toc ul {
            list-style: none;
        }

        .toc li {
            margin-bottom: 0.5rem;
        }

        .toc a {
            color: #0066cc;
            text-decoration: none;
            font-size: 1.1rem;
        }

        .toc a:hover {
            text-decoration: underline;
        }

        /* FAQ Sections */
        .faq-section {
            background: white;
            border-radius: 16px;
            padding: 3rem;
            margin-bottom: 2rem;
            box-shadow: 0 2px 8px rgba(0,0,0,0.08);
        }

        .faq-section h2 {
            font-size: 2rem;
            color: #333;
            margin-bottom: 2rem;
            padding-bottom: 1rem;
            border-bottom: 2px solid #e5e5e5;
        }

        .faq-item {
            margin-bottom: 2.5rem;
        }

        .faq-item:last-child {
            margin-bottom: 0;
        }

        .faq-question {
            font-size: 1.4rem;
            font-weight: 600;
            color: #333;
            margin-bottom: 1rem;
        }

        .faq-answer {
            font-size: 1.1rem;
            color: #555;
            line-height: 1.8;
        }

        /* Special Containers */
        .highlight-box {
            background: #fff9e6;
            border-left: 4px solid #ffc107;
            padding: 1.5rem;
            margin: 1.5rem 0;
            border-radius: 4px;
        }

        .case-study {
            background: #f0f7ff;
            border-left: 4px solid #0066cc;
            padding: 1.5rem;
            margin: 1.5rem 0;
            border-radius: 4px;
        }

        .case-study h3 {
            color: #0066cc;
            margin-bottom: 1rem;
        }

        .vatican-quote {
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            padding: 1.5rem;
            margin: 1.5rem 0;
            font-style: italic;
            border-radius: 4px;
        }

        .vatican-quote cite {
            display: block;
            margin-top: 1rem;
            font-style: normal;
            font-weight: 600;
            color: #6c757d;
        }

        /* Lists */
        .faq-answer ul, .faq-answer ol {
            margin: 1rem 0 1rem 2rem;
        }

        .faq-answer li {
            margin-bottom: 0.5rem;
            line-height: 1.7;
        }

        /* Bold emphasis */
        strong {
            color: #000;
            font-weight: 600;
        }

        /* Back Link */
        .back-link {
            display: inline-block;
            margin-top: 3rem;
            padding: 1rem 2rem;
            background: #000;
            color: white;
            text-decoration: none;
            border-radius: 8px;
            font-weight: 600;
        }

        .back-link:hover {
            background: #333;
        }

        /* Responsive */
        @media (max-width: 768px) {
            .page-title {
                font-size: 2rem;
            }
            
            .main-container {
                padding: 0 1rem;
            }
            
            .page-header, .faq-section {
                padding: 2rem;
            }

            .faq-question {
                font-size: 1.2rem;
            }

            .faq-answer {
                font-size: 1rem;
            }
        }
    </style>

    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "FAQPage",
  "mainEntity": [
    {
      "@type": "Question",
      "name": "Can AI replace doctors?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "No. According to Catholic teaching and medical ethics, AI should augment doctors, not replace them. <a href="../vatican-resources/liv-world-day-of-peace-2021-a-culture-of-care-as-a-path-to-peace.html">Read Vatican on culture of care</a> While AI can analyze medical images faster than humans or process vast amounts of patient data, it cannot provide the essential human elements of medical care. Medicine is more than diagnosis and treatment‚Äîit's a relationship between persons. Doctors provide: An AI can spot a tumor on an X-ray with remarkable accuracy. <a href="../blog/ethical-ai-educational-materials/implementing-vatican-ai-ethics-in-your-organization-a-practical-checklist.html">See practical AI ethics implementation guide</a> But it cannot sit with a frightened patient, explain what the diagnosis means f"
      }
    },
    {
      "@type": "Question",
      "name": "What can AI do well in healthcare?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "AI excels at specific, well-defined tasks that involve pattern recognition and data analysis: The key is that AI performs supporting roles‚Äîit gives doctors better tools, not replaces their judgment."
      }
    },
    {
      "@type": "Question",
      "name": "Where does AI fall short in medicine?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "AI's limitations in healthcare are significant and fundamental, touching on the very nature of what it means to practice medicine as a human endeavor. While AI excels at pattern recognition and data processing, it lacks the essential human qualities that make compassionate medical care possible‚Äîunderstanding context, navigating complex ethical situations, providing genuine empathy, and bearing moral responsibility for decisions that affect human lives and dignity."
      }
    },
    {
      "@type": "Question",
      "name": "What does \"Antiqua et Nova\" teach about AI in healthcare?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "The Vatican's January 2025 document dedicates substantial attention to healthcare AI, recognizing both its \"immense potential\" and serious risks. Key Vatican Concerns: The document warns specifically about:"
      }
    },
    {
      "@type": "Question",
      "name": "What is the Catholic principle of \"augmented intelligence\" vs. artificial intelligence?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "This distinction is crucial. The American Medical Association and Catholic medical ethicists prefer the term \"augmented intelligence\" over \"artificial intelligence\" when discussing healthcare applications. Catholic teaching strongly supports the first and opposes the second. Doctors should use AI to: But doctors must retain final authority over diagnosis and treatment. The human physician‚Äînot the algorithm‚Äîbears moral responsibility for patient care."
      }
    },
    {
      "@type": "Question",
      "name": "Does the Vatican oppose specific healthcare AI applications?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "The Vatican doesn't categorically oppose any healthcare AI technology, but it identifies applications requiring extreme caution: End-of-Life Decisions Using AI to determine whether to continue life support or recommend palliative care is deeply problematic. These decisions require understanding of patient values, family dynamics, religious beliefs, and the sacred dignity of human life‚Äîespecially at its end. Resource Allocation in Emergencies AI systems that determine who gets scarce medical reso"
      }
    },
    {
      "@type": "Question",
      "name": "Why is the doctor-patient relationship sacred in Catholic medical ethics?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "Catholic teaching views healthcare as fundamentally relational, not merely technical. The doctor-patient relationship embodies several key Christian values: 1. Recognizing Human Dignity A good doctor sees each patient as a unique person with inherent worth‚Äînot a case, a condition, or a data point. This reflects the Christian belief that every person is made in God's image. 2. Practicing Compassion The word \"compassion\" means \"to suffer with.\" Doctors who practice compassion enter into patients' "
      }
    },
    {
      "@type": "Question",
      "name": "How does AI risk \"dehumanizing\" healthcare?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "Dehumanization in healthcare happens when patients are treated as objects to be processed rather than persons to be cared for. AI risks accelerating this in several ways: 1. Screen-Centered Medicine Doctors increasingly focus on computer screens displaying AI recommendations rather than on patients. Eye contact decreases. Physical examination becomes perfunctory. The relationship suffers. 2. Algorithmic Decision-Making When doctors defer to AI recommendations without engaging their own clinical "
      }
    },
    {
      "@type": "Question",
      "name": "Can AI-powered chatbots provide adequate mental healthcare?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "This is an increasingly urgent question as AI chatbots marketed as \"mental health companions\" or \"therapy apps\" proliferate. Catholic medical ethics raises serious concerns: What Therapy Requires (That AI Cannot Provide): That said, AI tools could play supporting roles: scheduling appointments, providing psychoeducation, tracking mood patterns, offering coping skill reminders between therapy sessions‚Äîas long as they're clearly positioned as tools, not replacements for human therapists."
      }
    },
    {
      "@type": "Question",
      "name": "Should patients be told when AI is involved in their care?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "Yes, absolutely. Catholic medical ethics demands transparency and informed consent. Patients have a right to know: This means doctors should explain: \"An AI system analyzed your X-ray and flagged a potential issue. Based on my clinical examination, your symptoms, and my professional judgment, I agree with this finding...\" Not: \"The computer says you have...\" as if the AI made the diagnosis. Informed consent requires patients understand:"
      }
    },
    {
      "@type": "Question",
      "name": "What about AI and healthcare inequality?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "The Vatican specifically warns that AI could create \"medicine for the rich\" while the poor lack access to basic care. This violates Catholic Social Teaching's preferential option for the poor. The Risk: Ethical Deployment Would Mean:"
      }
    },
    {
      "@type": "Question",
      "name": "Who is morally responsible when AI-assisted diagnosis is wrong?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "This is a critical question as AI becomes more prevalent in medicine, touching on fundamental issues of accountability, justice, and the nature of moral agency itself. Catholic teaching is clear: humans must retain moral responsibility because only beings with free will and conscience can be held morally accountable for their actions. When AI makes an error that harms a patient, the responsibility falls on the healthcare professionals who chose to use and rely on that technology, the institutions that implemented it without adequate safeguards, and potentially the developers who created flawed or biased systems."
      }
    },
    {
      "@type": "Question",
      "name": "As a patient, how should I think about AI in my healthcare?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "Catholic teaching offers clear guidance for patients navigating AI in healthcare:"
      }
    },
    {
      "@type": "Question",
      "name": "For Catholic healthcare institutions: What principles should guide AI adoption?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "Catholic hospitals and healthcare systems have a special obligation to implement AI in ways that protect human dignity and serve the common good. Key Principles from Catholic Medical Ethics: 1. Person-Centered Care Remains Primary AI should support doctor-patient relationships, not replace them. Measure success by patient satisfaction and health outcomes, not just efficiency metrics. 2. Serve the Vulnerable First Deploy AI to improve care for underserved populations, not just to attract wealthy "
      }
    },
    {
      "@type": "Question",
      "name": "What's the Catholic vision for AI in healthcare?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "The Church's vision isn't anti-technology‚Äîit's pro-human. AI can and should serve healing, but always in ways that respect human dignity. The Vision: But this vision requires conscious choice. We must resist: Medicine is a vocation of service to human dignity. AI can be a powerful tool in that service‚Äîbut only if we keep the human person at the center."
      }
    }
  ]
}
    </script>
</head>

<body>
    <header class="header" id="main-header"></header>

    <main class="main-container">
        <div class="page-header">
            <h1 class="page-title">AI in Healthcare: When Should We Trust Machines with Life & Death?</h1>
            <p class="page-subtitle">Catholic teaching on medical AI, the doctor-patient relationship, and protecting human dignity in healthcare technology</p>
            <div class="view-counter">
                <span>üëÅÔ∏è</span>
                <span id="viewCount">Loading views...</span>
            </div>
        </div>

        <div class="toc">
            <h2>üìã Table of Contents</h2>
            <ul>
                <li><a href="#fundamentals">Healthcare AI Fundamentals (3 questions)</a></li>
                <li><a href="#vatican">What the Vatican Says (3 questions)</a></li>
                <li><a href="#doctor-patient">The Doctor-Patient Relationship (3 questions)</a></li>
                <li><a href="#ethical-boundaries">Ethical Boundaries (3 questions)</a></li>
                <li><a href="#practical">Practical Guidance (3 questions)</a></li>
            </ul>
        </div>

        <div class="faq-section" id="fundamentals">
            <h2>Healthcare AI Fundamentals</h2>

            <div class="faq-item">
                <h3 class="faq-question">Can AI replace doctors?</h3>
                <p class="faq-answer">No. According to Catholic teaching and medical ethics, AI should <strong>augment</strong> doctors, not replace them. While AI can analyze medical images faster than humans or process vast amounts of patient data, it cannot provide the essential human elements of medical care.</p>

                <div class="vatican-quote">
                    "AI should be used as a tool to complement human intelligence, rather than replace it."
                    <cite>‚Äî <a href="../vatican-resources/htmldocs/antiqua-et-nova-2025.html" target="_blank">Antiqua et Nova (2025)</a></cite>
                </div>

                <p class="faq-answer">Medicine is more than diagnosis and treatment‚Äîit's a <strong>relationship</strong> between persons. <a href="../vatican-resources/liv-world-day-of-peace-2021-a-culture-of-care-as-a-path-to-peace.html">Read Vatican teaching on culture of care</a> Doctors provide:</p>
                <ul class="faq-answer">
                    <li><strong>Empathy and compassion</strong> when delivering difficult news</li>
                    <li><strong>Understanding of patient values</strong> and life circumstances</li>
                    <li><strong>Ethical judgment</strong> in complex situations</li>
                    <li><strong>Trust-building</strong> that enables honest communication</li>
                    <li><strong>Moral responsibility</strong> for treatment decisions</li>
                </ul>

                <p class="faq-answer">An AI can spot a tumor on an X-ray with remarkable accuracy. <a href="../blog/ethical-ai-educational-materials/implementing-vatican-ai-ethics-in-your-organization-a-practical-checklist.html">See practical AI ethics implementation guide</a> But it cannot sit with a frightened patient, explain what the diagnosis means for their life, help them weigh treatment options against their values, or hold their hand when they cry.</p>
            </div>

            <div class="faq-item">
                <h3 class="faq-question">What can AI do well in healthcare?</h3>
                <p class="faq-answer">AI excels at specific, well-defined tasks that involve pattern recognition and processing vast amounts of data. In medical imaging, AI can analyze X-rays, MRIs, and CT scans to detect anomalies that human eyes might miss, often with remarkable speed and accuracy. AI systems can process thousands of medical records to identify drug interactions, predict patient deterioration, or suggest diagnoses based on symptoms and test results. For administrative tasks like scheduling, billing, and documentation, AI can reduce the burden on healthcare workers, freeing them to focus on direct patient care. However, these capabilities remain tools to augment human judgment, not replace the essential human elements of medical practice.</p>

                <div class="highlight-box">
                    <p><strong>Diagnostic Support:</strong></p>
                    <ul>
                        <li>Analyzing medical images (X-rays, CT scans, MRIs)</li>
                        <li>Detecting patterns in pathology slides</li>
                        <li>Identifying subtle changes in skin lesions</li>
                        <li>Flagging potential drug interactions</li>
                    </ul>

                    <p><strong>Administrative Efficiency:</strong></p>
                    <ul>
                        <li>Streamlining medical record documentation</li>
                        <li>Scheduling and resource allocation</li>
                        <li>Insurance claim processing</li>
                        <li>Reducing paperwork burden on doctors</li>
                    </ul>

                    <p><strong>Research and Development:</strong></p>
                    <ul>
                        <li>Drug discovery and development</li>
                        <li>Analyzing clinical trial data</li>
                        <li>Identifying disease patterns in populations</li>
                        <li>Predicting disease progression</li>
                    </ul>
                </div>

                <p class="faq-answer">The key is that AI performs <strong>supporting roles</strong>‚Äîit gives doctors better tools, not replaces their judgment.</p>
            </div>

            <div class="faq-item">
                <h3 class="faq-question">What are AI's limitations in medicine?</h3>
                <p class="faq-answer">AI's limitations in healthcare are significant and fundamental, touching on the very nature of what it means to practice medicine as a human endeavor. While AI excels at pattern recognition and data processing, it lacks the essential human qualities that make compassionate medical care possible‚Äîunderstanding context, navigating complex ethical situations, providing genuine empathy, and bearing moral responsibility for decisions that affect human lives and dignity.</p>

                <p class="faq-answer"><strong>1. No Understanding of Context</strong></p>
                <p class="faq-answer">An AI might recommend aggressive cancer treatment based on statistical outcomes, but it doesn't know the patient is a 92-year-old who values comfort over life extension, or a young parent desperate to try anything.</p>

                <p class="faq-answer"><strong>2. Cannot Navigate Ethical Gray Areas</strong></p>
                <p class="faq-answer">Medicine is full of situations without clear right answers‚Äîend-of-life decisions, treatment conflicts with religious beliefs, resource allocation in emergencies. These require prudential judgment AI cannot provide.</p>

                <p class="faq-answer"><strong>3. No Capacity for Empathy</strong></p>
                <p class="faq-answer">AI can generate sympathetic-sounding text, but it doesn't <em>feel</em> compassion. It cannot genuinely care about patients as persons.</p>

                <p class="faq-answer"><strong>4. Lacks Moral Responsibility</strong></p>
                <p class="faq-answer">When treatment goes wrong, an AI cannot be held morally accountable. Only humans can bear responsibility for medical decisions.</p>

                <div class="vatican-quote">
                    "If AI were to replace the doctor-patient relationship... it would reduce medical care to a mere technical procedure, robbing it of its deeply human and relational dimensions."
                    <cite>‚Äî <a href="../vatican-resources/htmldocs/antiqua-et-nova-2025.html" target="_blank">Antiqua et Nova (2025)</a></cite>
                </div>
            </div>
        </div>

        <div class="faq-section" id="vatican">
            <h2>What the Vatican Says</h2>

            <div class="faq-item">
                <h3 class="faq-question">What does "Antiqua et Nova" <a href="../vatican-resources/htmldocs/antiqua-et-nova-2025.html">Read the complete document</a> teach about AI in healthcare?</h3>
                <p class="faq-answer">The Vatican's 2025 document "Antiqua et Nova" <a href="../vatican-resources/htmldocs/antiqua-et-nova-2025.html">Read the complete document</a> dedicates significant attention to AI in healthcare, emphasizing that medical AI must always serve the human person and never reduce patients to data points or diagnoses to algorithms. The document stresses that healthcare is fundamentally a relationship of trust and care between persons‚Äîdoctor and patient‚Äîwhich requires human presence, compassion, and moral discernment that AI cannot provide. While AI can be a valuable diagnostic tool, the practice of medicine demands human judgment about the whole person, considering not just biological factors but psychological, social, and spiritual dimensions of health and healing that only human physicians can truly grasp.</p>

                <div class="case-study">
                    <h3>Real-World Example: Epic's Sepsis Prediction Algorithm</h3>
                    <p><strong>The Promise:</strong> Epic Systems deployed an AI algorithm across hundreds of hospitals to predict which patients would develop sepsis, a life-threatening condition requiring urgent treatment.</p>
                    <p><strong>The Problem:</strong> Investigation revealed the algorithm missed most sepsis cases while generating numerous false alarms, leading to alert fatigue where doctors began ignoring warnings.</p>
                    <p><strong>The Catholic Lesson:</strong> This demonstrates the danger of over-reliance on AI in life-or-death medical decisions. Healthcare AI must be rigorously validated, continuously monitored, and always subject to experienced clinical judgment. Human physicians must maintain ultimate responsibility for patient care.</p>
                    <p class="case-study-source">
                        <small>Source: <a href="https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2781307" target="_blank" rel="noopener noreferrer">JAMA Internal Medicine, June 2021</a></small>
                    </p>
                </div>


                <p class="faq-answer"><strong>Key Vatican Concerns:</strong></p>

                <div class="vatican-quote">
                    "While AI promises to boost productivity in healthcare, current approaches to the technology can paradoxically deskill workers, subject them to automated surveillance, and relegate them to rigid and repetitive tasks."
                    <cite>‚Äî <a href="../vatican-resources/htmldocs/antiqua-et-nova-2025.html" target="_blank">Antiqua et Nova (2025)</a></cite>
                </div>

                <p class="faq-answer">The document warns specifically about:</p>
                <ul class="faq-answer">
                    <li><strong>Replacing relationships with algorithms:</strong> The doctor-patient relationship is sacred in Catholic medical ethics‚Äîbuilt on trust, empathy, and personal knowledge</li>
                    <li><strong>Amplifying healthcare inequality:</strong> "Medicine for the rich" where advanced AI tools are available only to wealthy patients while others lack basic care</li>
                    <li><strong>Loss of clinical judgment:</strong> Doctors becoming mere implementers of AI recommendations rather than exercising prudential wisdom</li>
                    <li><strong>Privacy violations:</strong> Patient medical data used to train AI without proper consent or protection</li>
                </ul>
            </div>

            <div class="faq-item">
                <h3 class="faq-question">What is the Catholic principle of "augmented intelligence" vs. artificial intelligence?</h3>
                <p class="faq-answer">This distinction is crucial and represents a fundamental philosophical divide in how we approach medical technology. The American Medical Association and Catholic medical ethicists prefer the term <strong>"augmented intelligence"</strong> over "artificial intelligence" when discussing healthcare applications because it better captures the proper relationship between human physicians and AI tools‚Äîone where technology enhances rather than replaces human judgment, where algorithms inform rather than dictate decisions, and where the sacred doctor-patient relationship remains at the center of medical care.</p>

                <div class="highlight-box">
                    <p><strong>Augmented Intelligence:</strong> AI as a tool that enhances human capabilities while keeping humans in control</p>
                    <p><strong>Artificial Intelligence:</strong> AI as a replacement for human decision-making</p>
                </div>

                <p class="faq-answer">Catholic teaching strongly supports the first and opposes the second. Doctors should use AI to:</p>
                <ul class="faq-answer">
                    <li>Access more comprehensive diagnostic information</li>
                    <li>Identify patterns they might miss</li>
                    <li>Free up time from paperwork to spend with patients</li>
                    <li>Make more informed decisions</li>
                </ul>

                <p class="faq-answer">But <strong>doctors must retain final authority</strong> over diagnosis and treatment. The human physician‚Äînot the algorithm‚Äîbears moral responsibility for patient care.</p>
            </div>

            <div class="faq-item">
                <h3 class="faq-question">Does the Vatican oppose specific healthcare AI applications?</h3>
                <p class="faq-answer">The Vatican doesn't categorically oppose any healthcare AI technology, recognizing that these tools can serve the common good when properly deployed. However, it identifies several applications requiring extreme caution due to their potential to violate human dignity, reduce persons to data points, or create unjust disparities in care. The Church's concern focuses particularly on AI systems that make life-and-death decisions, allocate scarce resources, or predict human behavior in ways that could lead to discrimination against vulnerable populations.</p>

                <p class="faq-answer"><strong>End-of-Life Decisions</strong></p>
                <p class="faq-answer">Using AI to determine whether to continue life support or recommend palliative care is deeply problematic. These decisions require understanding of patient values, family dynamics, religious beliefs, and the sacred dignity of human life‚Äîespecially at its end.</p>

                <p class="faq-answer"><strong>Resource Allocation in Emergencies</strong></p>
                <p class="faq-answer">AI systems that determine who gets scarce medical resources (ventilators during a pandemic, organs for transplant) risk reducing humans to statistical calculations of value. Catholic teaching insists every life has equal dignity.</p>

                <p class="faq-answer"><strong>Predictive Risk Scoring</strong></p>
                <p class="faq-answer">Using AI to predict which patients will become expensive to treat or likely to sue creates perverse incentives that could lead doctors to avoid caring for vulnerable populations.</p>

                <div class="vatican-quote">
                    "Healthcare must remain centered on the person, not on data or algorithms. The patient is always a subject to be cared for, never an object to be optimized."
                    <cite>‚Äî Vatican principles from Antiqua et Nova</cite>
                </div>
            </div>
        </div>

        <div class="faq-section" id="doctor-patient">
            <h2>The Doctor-Patient Relationship</h2>

            <div class="faq-item">
                <h3 class="faq-question">Why is the doctor-patient relationship sacred in Catholic medical ethics?</h3>
                <p class="faq-answer">Catholic teaching views healthcare as fundamentally <strong>relational</strong>, not merely technical, rooted in the Gospel call to heal the sick and care for the vulnerable. <a href="ai-consciousness-souls-faq.html">Learn what makes humans irreplaceable in medicine</a> The doctor-patient relationship embodies the Church's understanding of human dignity, where each person is seen as made in God's image, deserving of compassionate care that addresses not just physical ailments but the whole person‚Äîbody, mind, and spirit. This sacred trust between healer and patient reflects Christ's own ministry of healing and represents a covenant of care that no algorithm can replicate.</p>

                <p class="faq-answer"><strong>1. Recognizing Human Dignity</strong></p>
                <p class="faq-answer">A good doctor sees each patient as a unique person with inherent worth‚Äînot a case, a condition, or a data point. This reflects the Christian belief that every person is made in God's image.</p>

                <p class="faq-answer"><strong>2. Practicing Compassion</strong></p>
                <p class="faq-answer">The word "compassion" means "to suffer with." Doctors who practice compassion enter into patients' suffering, bearing witness to their pain and offering healing presence‚Äînot just technical intervention.</p>

                <p class="faq-answer"><strong>3. Building Trust</strong></p>
                <p class="faq-answer">Effective medicine requires patients to be vulnerable‚Äîto share intimate details, to follow difficult treatment plans, to trust recommendations that may be uncomfortable. This trust is built through relationship, not algorithms.</p>

                <p class="faq-answer"><strong>4. Exercising Prudential Judgment</strong></p>
                <p class="faq-answer">The best medical decisions emerge from dialogue between doctor and patient, weighing clinical evidence against the patient's values, life circumstances, and goals.</p>

                <div class="case-study">
                    <h3>Real-World Example: The Value of Knowing Your Patient</h3>
                    <p><strong>The Scenario:</strong> An AI analyzes a 75-year-old man's test results and recommends aggressive chemotherapy for cancer, citing a 40% five-year survival rate.</p>
                    
                    <p><strong>What AI Doesn't Know:</strong> The patient is a devout Catholic who recently lost his wife, has no close family, struggles with depression, and values quality of life over quantity. His faith gives him peace about death, but he fears prolonged suffering.</p>
                    
                    <p><strong>The Human Doctor's Response:</strong> Takes time to understand the patient's values, discusses less aggressive palliative options, connects him with pastoral care, and helps him make a decision aligned with his dignity and faith‚Äîchoosing comfort over aggressive treatment.</p>
                    
                    <p><strong>The Catholic Perspective:</strong> The AI gave statistically optimal advice. The doctor gave personally appropriate care. Medicine is person-centered, not data-centered.</p>
                </div>
            </div>

            <div class="faq-item">
                <h3 class="faq-question">How does AI risk "dehumanizing" healthcare?</h3>
                <p class="faq-answer">Dehumanization in healthcare happens when patients are treated as objects to be processed rather than persons to be cared for, reducing the healing art to a mechanical transaction. AI risks accelerating this troubling trend by introducing layers of technological mediation between doctor and patient, encouraging efficiency metrics over genuine care, and subtly shifting medical culture from one focused on relationships to one obsessed with data optimization. When doctors spend more time looking at screens than into patients' eyes, when algorithms dictate treatment protocols without considering individual circumstances, and when healthcare becomes assembly-line medicine, we lose the human touch that makes healing possible.</p>

                <p class="faq-answer"><strong>1. Screen-Centered Medicine</strong></p>
                <p class="faq-answer">Doctors increasingly focus on computer screens displaying AI recommendations rather than on patients. Eye contact decreases. Physical examination becomes perfunctory. The relationship suffers.</p>

                <p class="faq-answer"><strong>2. Algorithmic Decision-Making</strong></p>
                <p class="faq-answer">When doctors defer to AI recommendations without engaging their own clinical judgment, medicine becomes mechanical‚Äîfollowing protocols rather than exercising wisdom.</p>

                <p class="faq-answer"><strong>3. Erosion of Clinical Skills</strong></p>
                <p class="faq-answer">Over-reliance on AI diagnostic tools can cause doctors to lose hands-on examination skills and clinical intuition‚Äîthe art of medicine that complements its science.</p>

                <p class="faq-answer"><strong>4. Reduced Time for Care</strong></p>
                <p class="faq-answer">While AI promises to free up doctor time, healthcare systems often respond by increasing patient loads‚Äîmore patients per hour, less time for each individual.</p>

                <div class="vatican-quote">
                    "AI can lead to harmful isolation... reducing human relationships to mere transactions facilitated by algorithms."
                    <cite>‚Äî <a href="../vatican-resources/htmldocs/antiqua-et-nova-2025.html" target="_blank">Antiqua et Nova (2025)</a></cite>
                </div>
            </div>

            <div class="faq-item">
                <h3 class="faq-question">Can AI-powered chatbots provide adequate mental healthcare?</h3>
                <p class="faq-answer">This is an increasingly urgent question as AI chatbots marketed as "mental health companions" or "therapy apps" proliferate, promising accessible mental healthcare but potentially delivering something far more superficial. Catholic medical ethics raises serious concerns about these technologies, particularly their inability to provide the authentic human connection essential for psychological healing. While these tools might offer basic coping strategies or serve as digital journals, they cannot replace the transformative power of genuine therapeutic relationships where vulnerable souls find understanding, acceptance, and the courage to heal through authentic human encounter.</p>

                <p class="faq-answer"><strong>What Therapy Requires (That AI Cannot Provide):</strong></p>
                <ul class="faq-answer">
                    <li><strong>Genuine empathy:</strong> Feeling compassion for another person's suffering, not just generating empathetic-sounding responses</li>
                    <li><strong>Moral responsibility:</strong> A therapist can be held accountable for harm; an algorithm cannot</li>
                    <li><strong>Contextual understanding:</strong> Grasping the unique complexity of a person's life, relationships, and circumstances</li>
                    <li><strong>Ethical boundaries:</strong> Recognizing when a patient is at risk and taking appropriate action</li>
                    <li><strong>Human presence:</strong> The healing power of being genuinely known and cared for by another person</li>
                </ul>

                <div class="highlight-box">
                    <strong>Vatican Concern:</strong> Antiqua et Nova specifically warns about "using AI to deceive in human relationships" and "anthropomorphizing AI" which "poses problems for children's growth." Treating chatbots as real therapists is a form of deception‚Äîto ourselves and especially to vulnerable populations.
                </div>

                <p class="faq-answer">That said, AI tools could play supporting roles: scheduling appointments, providing psychoeducation, tracking mood patterns, offering coping skill reminders between therapy sessions‚Äîas long as they're clearly positioned as tools, not replacements for human therapists.</p>
            </div>
        </div>

        <div class="faq-section" id="ethical-boundaries">
            <h2>Ethical Boundaries</h2>

            <div class="faq-item">
                <h3 class="faq-question">Should patients be told when AI is involved in their care?</h3>
                <p class="faq-answer"><strong>Yes, absolutely.</strong> Catholic medical ethics demands transparency and informed consent as fundamental requirements for respecting patient autonomy and human dignity. Patients have a right to know when artificial intelligence plays a role in their diagnosis or treatment, just as they have a right to know about any other aspect of their care. This transparency builds trust, enables truly informed decision-making, and ensures patients can raise concerns about AI use that might conflict with their values or preferences. Concealing AI involvement violates the covenant of honesty that must exist between healthcare providers and those they serve.</p>

                <ul class="faq-answer">
                    <li>When AI analyzes their medical images or data</li>
                    <li>What role AI recommendations play in diagnosis or treatment decisions</li>
                    <li>Whether their medical data will be used to train AI systems</li>
                    <li>How AI-generated insights influence their doctor's recommendations</li>
                </ul>

                <div class="vatican-quote">
                    "Misrepresenting AI as a person should always be avoided; doing so for fraudulent purposes is a grave ethical violation that could erode social trust."
                    <cite>‚Äî <a href="../vatican-resources/htmldocs/antiqua-et-nova-2025.html" target="_blank">Antiqua et Nova (2025)</a></cite>
                </div>

                <p class="faq-answer">This means doctors should explain: "An AI system analyzed your X-ray and flagged a potential issue. Based on my clinical examination, your symptoms, and my professional judgment, I agree with this finding..." Not: "The computer says you have..." as if the AI made the diagnosis.</p>

                <p class="faq-answer"><strong>Informed consent requires patients understand:</strong></p>
                <ul class="faq-answer">
                    <li>The human doctor remains responsible for all medical decisions</li>
                    <li>AI is a tool that assists diagnosis, not a replacement for human judgment</li>
                    <li>They can request human-only review of AI findings if desired</li>
                    <li>How their medical privacy is protected when AI is involved</li>
                </ul>
            </div>

            <div class="faq-item">
                <h3 class="faq-question">What about AI and healthcare inequality?</h3>
                <p class="faq-answer">Catholic teaching emphasizes the preferential option for the poor, demanding special attention to how healthcare AI affects vulnerable populations. Currently, AI in healthcare risks deepening existing inequalities in multiple ways: expensive AI systems may only be available in wealthy hospitals and regions, creating a two-tier system. AI trained primarily on data from well-resourced populations may perform poorly for underserved communities. Algorithmic bias can systematically deny care to already marginalized patients. The Church insists that healthcare AI must be developed and deployed with explicit attention to serving the poor and reducing disparities, not concentrating benefits among those already privileged with access to the best care.</p>

                <p class="faq-answer"><strong>The Risk:</strong></p>
                <ul class="faq-answer">
                    <li>Wealthy patients get AI-powered personalized medicine, early disease detection, optimized treatments</li>
                    <li>Poor patients in underserved areas lack even basic healthcare access</li>
                    <li>Research focuses on profitable AI applications rather than diseases affecting poor populations</li>
                    <li>Healthcare systems invest in expensive AI rather than hiring more doctors/nurses for underserved communities</li>
                </ul>

                <div class="highlight-box">
                    <strong>Catholic Principle:</strong> Technology should serve the common good, prioritizing the needs of the vulnerable. Healthcare AI should be developed and deployed to <em>reduce</em> disparities, not amplify them.
                </div>

                <p class="faq-answer"><strong>Ethical Deployment Would Mean:</strong></p>
                <ul class="faq-answer">
                    <li>Using AI to bring healthcare to remote/underserved areas (telemedicine support)</li>
                    <li>Prioritizing AI applications for diseases affecting poor populations</li>
                    <li>Ensuring AI diagnostic tools are validated across diverse populations</li>
                    <li>Making healthcare AI tools affordable and accessible to all hospitals</li>
                </ul>
            </div>

            <div class="faq-item">
                <h3 class="faq-question">Who bears moral responsibility when AI-assisted diagnosis is wrong?</h3>
                <p class="faq-answer">This is a critical question as AI becomes more prevalent in medicine, touching on fundamental issues of accountability, justice, and the nature of moral agency itself. Catholic teaching is clear: <strong>humans must retain moral responsibility</strong> because only beings with free will and conscience can be held morally accountable for their actions. When AI makes an error that harms a patient, the responsibility falls on the healthcare professionals who chose to use and rely on that technology, the institutions that implemented it without adequate safeguards, and potentially the developers who created flawed or biased systems. This isn't about blame-shifting but about maintaining the essential link between decision-making and moral accountability.</p>

                <p class="faq-answer">An AI can malfunction, produce errors, or reflect biases in its training data. But it cannot be morally responsible because:</p>
                <ul class="faq-answer">
                    <li>It has no conscience</li>
                    <li>It cannot understand the consequences of its errors</li>
                    <li>It cannot feel guilt or be held accountable</li>
                    <li>It is not a moral agent</li>
                </ul>

                <div class="vatican-quote">
                    "Only the human person can be morally responsible. AI should be guided by human intelligence‚Äînot the other way around."
                    <cite>‚Äî <a href="../vatican-resources/htmldocs/antiqua-et-nova-2025.html" target="_blank">Antiqua et Nova (2025)</a></cite>
                </div>

                <p class="faq-answer"><strong>In practice, this means:</strong></p>
                <ul class="faq-answer">
                    <li><strong>The doctor is responsible</strong> for accepting or rejecting AI recommendations</li>
                    <li><strong>Healthcare systems are responsible</strong> for choosing appropriate AI tools and validating their accuracy</li>
                    <li><strong>AI developers are responsible</strong> for testing systems thoroughly and disclosing limitations</li>
                    <li><strong>"The AI made a mistake" is not a valid excuse</strong> for medical errors‚Äîhumans chose to deploy and trust that AI</li>
                </ul>
            </div>
        </div>

        <div class="faq-section" id="practical">
            <h2>Practical Guidance</h2>

            <div class="faq-item">
                <h3 class="faq-question">How should patients think about AI in their healthcare?</h3>
                <p class="faq-answer">As a patient, you have the right to know when AI is involved in your care and to understand its role in diagnostic or treatment decisions. Don't hesitate to ask your healthcare providers how AI tools are being used, what their limitations are, and how much weight they're given in decisions about your care. Ensure that a qualified human physician reviews and takes full responsibility for all AI-assisted recommendations. Remember that while AI can be a valuable diagnostic aid processing data faster than humans, the practice of medicine requires human judgment, compassion, ethical reasoning, and the sacred trust of the doctor-patient relationship that no algorithm can replace. <a href="../vatican-resources/participation-of-the-holy-father-francis-at-the-g7-in-borgo-egnazia-puglia-14-june-2024.html">Read Pope Francis on AI at G7</a> You deserve care from persons, not just data analysis from machines.</p>

                <div class="highlight-box">
                    <p><strong>1. Value Your Doctor's Human Judgment</strong></p>
                    <p>If your doctor says "The AI recommends X, but based on knowing you and your values, I think Y would be better," trust that human judgment. Your doctor's knowledge of you as a person matters.</p>

                    <p><strong>2. Ask Questions About AI's Role</strong></p>
                    <p>You have a right to know: "Did AI analyze my test results? How confident are you in its findings? Did you personally review my images/data?"</p>

                    <p><strong>3. Insist on Human Connection</strong></p>
                    <p>If your doctor spends the appointment staring at screens, ask for eye contact and conversation. The relationship matters for your healing.</p>

                    <p><strong>4. Be Wary of AI-Only Healthcare</strong></p>
                    <p>Chatbot diagnoses, AI-only mental health apps, or telemedicine with no human doctor review should concern you. Seek care that includes human clinical judgment.</p>

                    <p><strong>5. Protect Your Medical Privacy</strong></p>
                    <p>Ask: "Will my data train AI systems? Who has access? How is it protected?" You can often opt out of data sharing.</p>
                </div>
            </div>

            <div class="faq-item">
                <h3 class="faq-question">What principles should guide Catholic healthcare institutions adopting AI?</h3>
                <p class="faq-answer">Catholic hospitals and healthcare systems have a special obligation to implement AI in ways that protect human dignity and serve the common good, setting an example for ethical technology use in healthcare. As institutions founded on Christ's healing ministry, they must ensure that AI adoption enhances rather than undermines their mission to serve the sick with compassion, prioritize the vulnerable, and treat each patient as a unique person made in God's image. This means going beyond mere regulatory compliance to embody a distinctively Catholic approach that puts human relationships, moral discernment, and spiritual care at the center of technologically-enhanced medicine.</p>

                <p class="faq-answer"><strong>Key Principles from Catholic Medical Ethics:</strong></p>

                <p class="faq-answer"><strong>1. Person-Centered Care Remains Primary</strong></p>
                <p class="faq-answer">AI should support doctor-patient relationships, not replace them. <a href="catholic-ai-ethics-faq.html">See complete Catholic AI ethics framework</a> Measure success by patient satisfaction and health outcomes, not just efficiency metrics.</p>

                <p class="faq-answer"><strong>2. Serve the Vulnerable First</strong></p>
                <p class="faq-answer">Deploy AI to improve care for underserved populations, not just to attract wealthy patients. Use AI to bring care to those who lack access.</p>

                <p class="faq-answer"><strong>3. Maintain Human Oversight</strong></p>
                <p class="faq-answer">No AI recommendation should be implemented without human clinical review. Doctors must be able to override AI when their judgment differs.</p>

                <p class="faq-answer"><strong>4. Ensure Transparency</strong></p>
                <p class="faq-answer">Patients should know when AI is used in their care. Healthcare workers should understand how AI systems make recommendations.</p>

                <p class="faq-answer"><strong>5. Protect Privacy Rigorously</strong></p>
                <p class="faq-answer">Patient data used to train AI must be properly de-identified. Sharing data with tech companies requires informed consent.</p>

                <p class="faq-answer"><strong>6. Invest in Staff Formation</strong></p>
                <p class="faq-answer">Train doctors, nurses, and staff not just in using AI tools, but in maintaining the human dimensions of care amid technological change.</p>
            </div>

            <div class="faq-item">
                <h3 class="faq-question">What is the Catholic vision for AI in healthcare?</h3>
                <p class="faq-answer">The Church's vision isn't anti-technology‚Äîit's pro-human, embracing AI as a powerful tool for healing while insisting it remain subordinate to the sacred mission of caring for the whole person. Catholic teaching envisions a healthcare future where artificial intelligence amplifies human compassion rather than replacing it, where technology serves to free healthcare workers for more meaningful patient interaction rather than reducing them to data entry clerks, and where the poorest and most vulnerable benefit from medical advances rather than being left further behind. This vision calls for AI that respects the mystery and dignity of human life at every stage.</p>

                <div class="vatican-quote">
                    "AI has immense potential to improve healthcare outcomes without losing the essential humanity of human dignity in medical practice."
                    <cite>‚Äî Catholic medical ethics principles</cite>
                </div>

                <p class="faq-answer"><strong>The Vision:</strong></p>
                <ul class="faq-answer">
                    <li><strong>Doctors spend more time with patients</strong> because AI handles administrative burdens</li>
                    <li><strong>Early disease detection improves</strong> through AI pattern recognition, but humans make treatment decisions</li>
                    <li><strong>Healthcare becomes more accessible</strong> to remote/underserved populations through AI-supported telemedicine</li>
                    <li><strong>Medical errors decrease</strong> because AI catches things human eyes miss, with human judgment providing final check</li>
                    <li><strong>Research accelerates</strong> through AI analysis of vast datasets, speeding development of treatments</li>
                </ul>

                <p class="faq-answer">But this vision requires conscious choice. We must resist:</p>
                <ul class="faq-answer">
                    <li>Treating patients as data points</li>
                    <li>Reducing medicine to algorithmic decision-making</li>
                    <li>Sacrificing doctor-patient relationships for efficiency</li>
                    <li>Creating healthcare inequality where AI serves the rich</li>
                    <li>Allowing profit motives to override patient welfare</li>
                </ul>

                <p class="faq-answer"><strong>Medicine is a vocation of service to human dignity.</strong> AI can be a powerful tool in that service‚Äîbut only if we keep the human person at the center.</p>
            </div>
        </div>
        <!-- Additional Resources from Vatican Archives -->
        <div class="faq-section" id="additional-resources">
            <h2>üìö Additional Vatican Resources</h2>
            
            <div class="faq-item">
                <h3 class="faq-question">Where can I find more Vatican documents on this topic?</h3>
                <p class="faq-answer">For deeper understanding from official Vatican sources, explore the rich tradition of Catholic teaching on healthcare ethics, human dignity, and technology's proper role in serving humanity. The Church has developed extensive guidance on these topics through papal encyclicals, Vatican dicastery documents, and statements from bishops' conferences worldwide. These resources offer both timeless principles rooted in Scripture and Tradition, as well as contemporary applications to emerging technologies like artificial intelligence, providing healthcare professionals, ethicists, and concerned Catholics with the theological and philosophical framework needed to navigate these complex issues.</p>
                
                <ul class="faq-answer">
                    <li><a href="../vatican-resources/htmldocs/antiqua-et-nova-2025.html" style="color: #0066cc; text-decoration: none; font-weight: 600;">Antiqua et Nova (2025)</a> - Latest Vatican guidance on medical AI</li>
                    <li><a href="../vatican-resources/htmldocs/pope-francis-centesimus-annus-ai-june-2024.html" style="color: #0066cc; text-decoration: none; font-weight: 600;">Centesimus Annus and AI (2024)</a> - Human dignity in healthcare technology</li>
                    <li><a href="../vatican-resources/htmldocs/pope-leo-xiv-tech-executives-vatican-june-2025.html" style="color: #0066cc; text-decoration: none; font-weight: 600;">Pope Leo XIV to Tech Leaders (2025)</a> - Ethical AI in medical applications</li>
                    <li><a href="../vatican-resources/htmldocs/towards-full-presence-social-media-2023.html" style="color: #0066cc; text-decoration: none; font-weight: 600;">Towards Full Presence (2023)</a> - Human presence in digital healthcare</li>
                </ul>
                
                <p class="faq-answer">These documents provide official Vatican perspectives, historical context, and theological foundations for understanding AI ethics from a Catholic perspective.</p>
            </div>
        </div>

        <!-- Related FAQs Section -->
        <div class="faq-section" id="related">
            <h2>Related FAQs</h2>
            <p class="faq-answer">Explore these related topics to deepen your understanding:</p>
            
            <ul class="faq-answer">
                <li><a href="ai-consciousness-souls-faq.html" style="color: #0066cc; text-decoration: none; font-weight: 600;">Can AI Have a Soul?</a> - AI decision-making in life and death</li>
                <li><a href="ai-bias-fairness-faq.html" style="color: #0066cc; text-decoration: none; font-weight: 600;">AI Bias & Fairness</a> - Healthcare algorithmic discrimination</li>
                <li><a href="ai-privacy-surveillance-faq.html" style="color: #0066cc; text-decoration: none; font-weight: 600;">AI Privacy & Surveillance</a> - Medical data protection</li>
            </ul>
        </div>

        <!-- Back Link -->
        <div class="faq-section">
            <a href="https://hoarhouse.github.io/dcfh/faqs/index.html" class="back-link">‚Üê Back to All FAQs</a>
        </div>
    </main>

    <!-- Footer will be injected by dcf-ui.js -->
    <footer id="main-footer"></footer>

    <!-- Scripts -->
    <script src="https://cdn.jsdelivr.net/npm/@supabase/supabase-js@2"></script>
    <script src="../js/dcf-core.js"></script>
    <script src="../js/dcf-ui.js"></script>
    <script src="../js/dcf-auth.js"></script>
    <script src="../js/dcf-analytics.js"></script>
    <script src="../js/dcf-init.js"></script>

    <script>
        // Display view count when page loads
        async function displayViewCount() {
            // Wait for dcfSupabase to be available
            if (!window.dcfSupabase) {
                setTimeout(displayViewCount, 100);
                return;
            }

            try {
                const currentPath = window.location.pathname;
                const normalizedPath = currentPath.endsWith('/') ? currentPath.slice(0, -1) : currentPath;
                
                // Construct the expected page URL format
                const pagePath = normalizedPath.includes('/faqs/') 
                    ? normalizedPath.split('/faqs/')[1] 
                    : normalizedPath.split('/').pop();
                
                const expectedUrl = `/dcfh/faqs/${pagePath}`;
                
                // Get view count for this FAQ page
                const { data, error } = await window.dcfSupabase
                    .from('universal_analytics')
                    .select('view_count')
                    .eq('page_url', expectedUrl)
                    .single();
                
                if (error || !data) {
                    console.log('No view data for:', expectedUrl);
                    const viewElement = document.getElementById('viewCount');
                    if (viewElement) viewElement.style.display = 'none';
                    return;
                }
                
                const viewElement = document.getElementById('viewCount');
                if (viewElement) {
                    viewElement.textContent = `${data.view_count.toLocaleString()} views`;
                }
                
            } catch (err) {
                console.log('View count error:', err);
                const viewElement = document.getElementById('viewCount');
                if (viewElement) viewElement.style.display = 'none';
            }
        }

        // Call when page loads
        if (document.readyState === 'loading') {
            document.addEventListener('DOMContentLoaded', displayViewCount);
        } else {
            displayViewCount();
        }
    </script>
</body>
</html>